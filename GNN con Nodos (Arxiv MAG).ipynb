{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GNN con Nodos (Arxiv MAG).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi0PCqOTKkfv"
      },
      "source": [
        "# Explorando GNN para prediccion de nodos\n",
        "\n",
        "1. Setup (librerias, datos, splits)\n",
        "2. EDA (como se ve el grafo?)\n",
        "3. Un GNN sencillo\n",
        "4. Un GraphNets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T13:00:31.536172Z",
          "start_time": "2020-04-07T13:00:31.532636Z"
        },
        "id": "v5lACW4qovun"
      },
      "source": [
        "\n",
        "# 1 - Setup\n",
        "## 1a  Bajar colab_utils + repo\n",
        "\n",
        "\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/beangoben/gnn_workshop_riiaa/blob/master/Prediccion de Nodos con Arxiv MAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-04-07T12:59:10.855114Z",
          "start_time": "2020-04-07T12:59:10.540431Z"
        },
        "id": "J5HaH9Yvovuo",
        "scrolled": true
      },
      "source": [
        "!wget https://raw.githubusercontent.com/beangoben/gnn_workshop_riiaa/master/colab_utils.py -O colab_utils.py\n",
        "!rm -rf sample_data\n",
        "github_repo = 'https://github.com/beangoben/gnn_workshop_riiaa'\n",
        "import colab_utils\n",
        "colab_utils.clone_repo(github_repo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYkzGZr5ovuw"
      },
      "source": [
        "## 1b Instala paquetes via pip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JV4hFB3UwFN8"
      },
      "source": [
        "if colab_utils.is_running_colab():\n",
        "    colab_utils.pip_install(['umap-learn', 'dm-sonnet', 'graph_nets', 'ogb', 'ml-collections'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-CPqE95ovu1"
      },
      "source": [
        "## 1c importa modulos\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:16:46.055749Z",
          "start_time": "2020-08-25T13:16:39.853397Z"
        },
        "id": "l7xIWY9Qovu8"
      },
      "source": [
        "import os\n",
        "from collections import OrderedDict, defaultdict\n",
        "\n",
        "import tqdm.auto as tqdm\n",
        "import colab_utils \n",
        "import ml_collections\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import altair as alt\n",
        "import networkx as nx\n",
        "\n",
        "import sklearn\n",
        "import umap\n",
        "import tensorflow as tf\n",
        "import sonnet as snt\n",
        "import graph_nets as gn\n",
        "import ogb\n",
        "\n",
        "colab_utils.print_module_versions([umap, tf, snt, nx, ogb])\n",
        "print(f'Tiene GPU? {tf.config.list_physical_devices(\"gpu\")}')\n",
        "colab_utils.matplotlib_settings()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjDRL90MpxOV"
      },
      "source": [
        "## 1d Bajar dataset via ogb (arxiv)\n",
        "\n",
        "https://ogb.stanford.edu/docs/nodeprop/#ogbn-arxiv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:16:47.326454Z",
          "start_time": "2020-08-25T13:16:46.060420Z"
        },
        "id": "SQ8JKbalphMa"
      },
      "source": [
        "from ogb.nodeproppred import NodePropPredDataset\n",
        "\n",
        "dataset = NodePropPredDataset(name = 'ogbn-arxiv')\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:16:47.341212Z",
          "start_time": "2020-08-25T13:16:47.329949Z"
        },
        "id": "48l8jLqCw_Ly"
      },
      "source": [
        "dataset.meta_info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_-UWpHcD97R"
      },
      "source": [
        "Datos relacionados a los papers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "X91cqSsNEKiN",
        "outputId": "868cc3ca-303a-49b2-d88f-d3e69d19914f"
      },
      "source": [
        "!wget https://snap.stanford.edu/ogb/data/misc/ogbn_arxiv/titleabs.tsv.gz -O titleabs.tsv.gz\n",
        "paper_df = pd.read_csv('titleabs.tsv.gz', sep='\\t', compression=\"gzip\", names=['paper id', 'title', 'abstract'],)\n",
        "paper_df = paper_df.drop(0,axis=0).dropna()\n",
        "paper_df['paper id'] = paper_df['paper id'].astype(int)\n",
        "paper_df.set_index('paper id', drop=True, inplace=True)\n",
        "paper_df"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "^C\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-214-4409a0712e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget https://snap.stanford.edu/ogb/data/misc/ogbn_arxiv/titleabs.tsv.gz -O titleabs.tsv.gz'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpaper_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'titleabs.tsv.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'abstract'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpaper_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpaper_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaper_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpaper_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'paper id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[0] not found in axis'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgPNTMnc20kN"
      },
      "source": [
        "## 1e Establecer categorias a predecir"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:16:47.362282Z",
          "start_time": "2020-08-25T13:16:47.343141Z"
        },
        "id": "lCEV5kvf20kP"
      },
      "source": [
        "def get_topk_labels(dataset, k=10):\n",
        "    \"\"\"Conseguir las categorias mas pobladas.\"\"\"\n",
        "    unique, counts = np.unique(dataset.labels.ravel(), return_counts=True)\n",
        "    sorted_labels = np.argsort(counts)[::-1]\n",
        "    \n",
        "    adf = pd.read_csv(os.path.join('dataset/ogbn_arxiv/mapping', 'labelidx2arxivcategeory.csv.gz'), compression=\"gzip\")\n",
        "    label_to_category = dict(zip(adf['label idx'], adf['arxiv category']))\n",
        "    top_labels = sorted_labels[:k]\n",
        "    return top_labels, [label_to_category[i] for i in top_labels]\n",
        "\n",
        "top_labels, categories = get_topk_labels(dataset, 10)\n",
        "N_LABELS = len(top_labels)\n",
        "top_labels, categories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:16:47.570908Z",
          "start_time": "2020-08-25T13:16:47.364009Z"
        },
        "id": "qJ71nopA20kg"
      },
      "source": [
        "def labels_to_nodecolors(labels, k=10):\n",
        "    \"\"\"Convierte etqiuetas a colores.\"\"\"\n",
        "    cols = sns.color_palette(\"Set3\", k)\n",
        "    return [cols[int(l)] for l in labels.ravel()]\n",
        "\n",
        "def plot_color_legend(k=10):\n",
        "    cols = sns.color_palette(\"Set3\", k)\n",
        "    sns.palplot(cols)\n",
        "    plt.xticks(np.arange(N_LABELS)-0.5, categories, rotation=45)\n",
        "    plt.show()\n",
        "    \n",
        "plot_color_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBgnXFTp20kr"
      },
      "source": [
        "## 1f Construir train-test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:18:08.723554Z",
          "start_time": "2020-08-25T13:16:47.573719Z"
        },
        "id": "fR49aasc20ku"
      },
      "source": [
        "def make_arxiv_subset(dataset, split, label_subset=None, large_cc=True):\n",
        "    \"\"\"Get a split of the arxiv dataset\"\"\"\n",
        "\n",
        "    n_edges = dataset.graph['edge_index'].shape[1]\n",
        "    n_nodes = dataset.graph['node_feat'].shape[0]\n",
        "    data_dict = {\n",
        "        'nodes':dataset.graph['node_feat'].astype(np.float32),\n",
        "        'edges':np.zeros((n_edges, 1),dtype=np.float32),\n",
        "        'senders':dataset.graph['edge_index'][0],\n",
        "        'receivers':dataset.graph['edge_index'][1],\n",
        "        'globals':np.zeros(1,dtype=np.float32),\n",
        "    }\n",
        "    y = dataset.labels\n",
        "    # Get paper ids\n",
        "    adf = pd.read_csv(os.path.join('dataset/ogbn_arxiv/mapping', 'nodeidx2paperid.csv.gz'), compression=\"gzip\")\n",
        "    paperids = adf['paper id'].values\n",
        "    # Convert to networkx\n",
        "    g = gn.utils_np.data_dict_to_networkx(data_dict)\n",
        "\n",
        "    # Subset by indices\n",
        "    indices = dataset.get_idx_split()[split]\n",
        "    y = y[indices]\n",
        "    paperids = paperids[indices]\n",
        "    g = g.subgraph(indices)\n",
        "    g = nx.relabel.convert_node_labels_to_integers(g)\n",
        "    print(len(indices), y.shape, len(g.nodes))\n",
        "\n",
        "    # Subset by labels\n",
        "    if label_subset is not None:\n",
        "        is_top = np.isin(y.ravel(), top_labels)\n",
        "        top_indices = np.arange(len(g.nodes))[is_top]\n",
        "        y = y[top_indices]\n",
        "        g = g.subgraph(top_indices)\n",
        "        g = nx.relabel.convert_node_labels_to_integers(g)\n",
        "        paperids = paperids[top_indices]\n",
        "\n",
        "    # Get largest component.\n",
        "    if large_cc:\n",
        "        gcc = list(sorted(nx.connected_components(g.to_undirected()), key=len, reverse=True)[0])\n",
        "        print(len(gcc), np.max(gcc), len(y))\n",
        "        g = g.subgraph(gcc)\n",
        "        g = nx.relabel.convert_node_labels_to_integers(g)\n",
        "        y = y[gcc]\n",
        "        paperids = paperids[gcc]\n",
        "    \n",
        "    # relabel labels to 0 to n-labels\n",
        "    new_labels = {j:i for i,j in enumerate(label_subset)}\n",
        "    y = np.array([new_labels[i] for i in y.ravel()]).reshape(-1,1)\n",
        "    return g, y, paperids\n",
        "\n",
        "g_train, y_train, paperids_train = make_arxiv_subset(dataset, 'train', top_labels, True)\n",
        "g_valid, y_valid, paperids_valid = make_arxiv_subset(dataset, 'valid', top_labels, False)\n",
        "\n",
        "print(len(g_train.nodes), len(y_train), len(paperids_train))\n",
        "print(len(g_valid.nodes), len(y_valid), len(paperids_valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF25wTpj20k5"
      },
      "source": [
        "# 2 A explorar datos! (EDA)\n",
        "\n",
        "## 2a: Los data dicts y graphtuples\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:18:11.961319Z",
          "start_time": "2020-08-25T13:18:08.725110Z"
        },
        "id": "YDPQy--C20k6"
      },
      "source": [
        "data_dict = gn.utils_np.networkx_to_data_dict(g_train)\n",
        "data_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pW-wh4EEC-hp"
      },
      "source": [
        "def nx_to_graph_stuple(g):\n",
        "    \"\"\"Convierte networkx a un GraphsTuple\"\"\"\n",
        "    return gn.utils_tf.data_dicts_to_graphs_tuple([gn.utils_np.networkx_to_data_dict(g)])\n",
        "\n",
        "x_train = nx_to_graph_stuple(g_train)\n",
        "x_valid = nx_to_graph_stuple(g_valid)\n",
        "x_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvFJHwpPDMLD"
      },
      "source": [
        "# Aplanamos los labels\n",
        "y_train = y_train.ravel()\n",
        "y_valid = y_valid.ravel()\n",
        "print(y_train.shape, y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbYR4hSC0NDz"
      },
      "source": [
        "## 2b explorando el espacio de nodos\n",
        "Visualizaremos la informacion en los nodos via umap\n",
        "\n",
        "Ojo, toma un poco de tiempo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:17.212379Z",
          "start_time": "2020-08-25T13:18:11.965176Z"
        },
        "id": "yovmX5kW20lK"
      },
      "source": [
        "import sklearn.pipeline\n",
        "import sklearn.preprocessing\n",
        "\n",
        "node_info = data_dict['nodes']\n",
        "print(node_info.shape)\n",
        "\n",
        "pipe = sklearn.pipeline.Pipeline([('scaler', sklearn.preprocessing.StandardScaler()),\n",
        "                                  ('dim_reduce', umap.UMAP())])\n",
        "node_umap = pipe.fit_transform(node_info)\n",
        "print(node_umap.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:18.384870Z",
          "start_time": "2020-08-25T13:19:17.214290Z"
        },
        "id": "NNfJgiti20lX"
      },
      "source": [
        "plot_color_legend()\n",
        "plt.scatter(node_umap[:,0], node_umap[:, 1],\n",
        "            c=labels_to_nodecolors(y_train),\n",
        "            s=1, alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T12:32:21.561632Z",
          "start_time": "2020-08-25T12:32:21.558964Z"
        },
        "id": "M_VDWMED20ln"
      },
      "source": [
        "### Interactivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:18.403466Z",
          "start_time": "2020-08-25T13:19:18.386193Z"
        },
        "id": "H53jaEW620lp"
      },
      "source": [
        "indices = np.random.permutation(len(node_umap))[:5000]\n",
        "\n",
        "vis_df = pd.DataFrame()\n",
        "vis_df['UMAP1'] = node_umap[indices, 0]\n",
        "vis_df['UMAP2'] = node_umap[indices, 1]\n",
        "vis_df['label'] = y_train[indices].ravel()\n",
        "vis_df['id'] = paperids_train[indices]\n",
        "vis_df['title'] = paper_df.loc[vis_df['id']]['title'].tolist()\n",
        "vis_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:18.573066Z",
          "start_time": "2020-08-25T13:19:18.405117Z"
        },
        "id": "5zaSsy6I20l0"
      },
      "source": [
        "alt.Chart(vis_df).mark_circle(size=10).encode(\n",
        "    x='UMAP1:Q',\n",
        "    y='UMAP2:Q',\n",
        "    color='label:N',\n",
        "    tooltip=['id', 'label', 'title']\n",
        ").interactive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K80N6czz20mD"
      },
      "source": [
        "## 2c: Vamos a crear mini-batches de grafos\n",
        "\n",
        "Para una version mas avanzada checa: https://arxiv.org/abs/2006.04311"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:18.644549Z",
          "start_time": "2020-08-25T13:19:18.641512Z"
        },
        "id": "J8YRRYpf20mT"
      },
      "source": [
        "def get_batch(x, y, center_node, radius=3, batch_size=128):\n",
        "    \"\"\"Sub-samplea el graph.\"\"\"\n",
        "    nx_graph = gn.utils_np.graphs_tuple_to_networkxs(x)[0].to_undirected()\n",
        "    sub_graph = nx.generators.ego_graph(nx_graph.to_undirected(),\n",
        "                                        n=center_node, radius=radius)\n",
        "    node_indices = list(sub_graph.nodes)[:batch_size]\n",
        "    g_batch = sub_graph.subgraph(node_indices)\n",
        "    g_batch = nx.relabel.convert_node_labels_to_integers(g_batch)\n",
        "    y_batch = y[node_indices].ravel()\n",
        "    return g_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:26.199987Z",
          "start_time": "2020-08-25T13:19:18.645723Z"
        },
        "id": "SZzLoaRA20mh"
      },
      "source": [
        "g_batch, y_batch = get_batch(x_train, y_train, center_node=0, radius=2)\n",
        "plot_color_legend()\n",
        "pos = nx.kamada_kawai_layout(g_batch)\n",
        "nx.draw(g_batch, pos, node_size=60, node_color=labels_to_nodecolors(y_batch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:19:30.107381Z",
          "start_time": "2020-08-25T13:19:30.103041Z"
        },
        "id": "k_6Fjus220nN"
      },
      "source": [
        "x_batch = nx_to_graph_stuple(g_batch)\n",
        "x_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T12:01:23.611610Z",
          "start_time": "2020-08-25T12:01:23.604859Z"
        },
        "id": "niTCJpyi20nY"
      },
      "source": [
        "# 3 Nuestro primer GNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:19.537332Z",
          "start_time": "2020-08-25T13:20:19.531687Z"
        },
        "id": "3gSlFS3O20nZ"
      },
      "source": [
        "def get_num_parameters(model: snt.Module, trainable: bool = True) -> int:\n",
        "  \"\"\"Numero de parametros.\"\"\"\n",
        "  variables = model.trainable_variables if trainable else model.variables\n",
        "  return int(np.sum([np.prod(v.shape) for v in variables]))\n",
        "\n",
        "\n",
        "def print_model(model: snt.Module):\n",
        "  \"\"\"Sumario de un modelo.\"\"\"\n",
        "  print(f'{model.__class__.__name__} : {model.name}\\n')\n",
        "  print(snt.format_variables(model.variables))\n",
        "  n_params = get_num_parameters(model, False)\n",
        "  trainable_params = get_num_parameters(model, True)\n",
        "  print(f'\\nParams: {trainable_params} trainable out of {n_params}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwJpKl0_20nq"
      },
      "source": [
        "## 3a - Bloque de transformacion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:20.483924Z",
          "start_time": "2020-08-25T13:20:20.410339Z"
        },
        "id": "RL3ioPM120ns"
      },
      "source": [
        "def make_mlp_model(latent_size=32, n_layers=2, add_head=0):\n",
        "    \"\"\"Crea un MLP luego pasando por un LayerNorm y opcionalmente una capa lineal.\"\"\"\n",
        "    layers = [\n",
        "        snt.nets.MLP([latent_size] * n_layers, activate_final=True),\n",
        "        snt.LayerNorm(axis=-1, create_offset=True, create_scale=True)]\n",
        "    if add_head > 0:\n",
        "        layers.append(snt.Linear(add_head))\n",
        "    return snt.Sequential(layers)\n",
        "    \n",
        "bloque = make_mlp_model(32, 2, 0)\n",
        "bloque(x_batch.nodes)\n",
        "print_model(bloque)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDg4Nr6a20n6"
      },
      "source": [
        "# 3b - Un GNN independiente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:24.701133Z",
          "start_time": "2020-08-25T13:20:24.662955Z"
        },
        "id": "shEbtZuZ20n8"
      },
      "source": [
        "gnn = gn.modules.GraphIndependent(node_model_fn=lambda: make_mlp_model(32, 2, N_LABELS))\n",
        "x_batch = nx_to_graph_stuple(g_batch)\n",
        "out = gnn(x_batch)\n",
        "print_model(gnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoO_t4vd20oJ"
      },
      "source": [
        "# 3c - A Entrenar !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:29.132084Z",
          "start_time": "2020-08-25T13:20:29.097482Z"
        },
        "id": "d-e17wDB20oM"
      },
      "source": [
        "NUM_ITER = 100\n",
        "optimizer = tf.optimizers.Adam(3e-4)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:29.779951Z",
          "start_time": "2020-08-25T13:20:29.761980Z"
        },
        "id": "02E6jLR420od"
      },
      "source": [
        "@tf.function(experimental_relax_shapes=True)\n",
        "def forward_pass(x):\n",
        "    \"\"\"Prediccion.\"\"\"\n",
        "    out_x = gnn(x)\n",
        "    return out_x.nodes\n",
        "\n",
        "def logits_to_stats(y_true, node_logits):\n",
        "    \"\"\"Convert predicted logits to class stats.\"\"\"\n",
        "    loss = loss_fn(y_true, node_logits)\n",
        "    probs = tf.nn.softmax(node_logits)\n",
        "    acc = metric(y_true, probs).numpy()\n",
        "    return loss.numpy(), acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:40.713670Z",
          "start_time": "2020-08-25T13:20:30.627262Z"
        },
        "id": "ljXow2pJ20ol"
      },
      "source": [
        "pbar = tqdm.tqdm(range(NUM_ITER))\n",
        "stats = defaultdict(list)\n",
        "\n",
        "for i in pbar:\n",
        "    with tf.GradientTape() as tape:\n",
        "      node_logits = forward_pass(x_train)\n",
        "      loss = loss_fn(y_train, node_logits)\n",
        "    grads = tape.gradient(loss, gnn.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, gnn.trainable_variables))\n",
        "    # Train statistics.\n",
        "    train_loss, train_acc = logits_to_stats(y_train, node_logits)\n",
        "    stats['train_loss'].append(train_loss)\n",
        "    stats['train_acc'].append(train_acc)\n",
        "    # Validation statistics.\n",
        "    node_logits = forward_pass(x_valid)\n",
        "    valid_loss, valid_acc = logits_to_stats(y_valid, node_logits)\n",
        "    stats['valid_loss'].append(valid_loss)\n",
        "    stats['valid_acc'].append(valid_acc)\n",
        "    # Update progress bar.\n",
        "    pbar.set_postfix({key:values[-1] for key, values in stats.items()})\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:54.538382Z",
          "start_time": "2020-08-25T13:20:53.753427Z"
        },
        "id": "4NQTm3db20ov"
      },
      "source": [
        "for key in ['train_loss','test_loss']:\n",
        "    plt.plot(stats[key],label=key)\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for key in ['train_acc','test_acc']:\n",
        "    plt.plot(stats[key],label=key)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZlTXSMw20o-"
      },
      "source": [
        "## 4 GNN mas avanzados: GraphNets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:58.348518Z",
          "start_time": "2020-08-25T13:20:58.206918Z"
        },
        "id": "YzBP2BJ220o_",
        "scrolled": true
      },
      "source": [
        "cabeza = gn.modules.GraphIndependent(\n",
        "    node_model_fn=lambda: make_mlp_model(32, 2, N_LABELS))\n",
        "\n",
        "gnn_layers = [gn.modules.GraphNetwork(\n",
        "    edge_model_fn=lambda: make_mlp_model(32, 2),\n",
        "    node_model_fn=lambda: make_mlp_model(32, 2),\n",
        "    global_model_fn=lambda: make_mlp_model(32, 2)) for i in range(3)]\n",
        "\n",
        "gnn = snt.Sequential( gnn_layers + [cabeza])\n",
        "x_batch = nx_to_graph_stuple(g_batch)\n",
        "out = gnn(x_batch)\n",
        "print_model(gnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:59.102450Z",
          "start_time": "2020-08-25T13:20:59.069612Z"
        },
        "id": "vE7TzFEo20pH"
      },
      "source": [
        "NUM_ITER = 100\n",
        "optimizer = tf.optimizers.Adam(3e-4)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:20:59.813451Z",
          "start_time": "2020-08-25T13:20:59.793890Z"
        },
        "id": "Ap6Nu4JJ20pR"
      },
      "source": [
        "@tf.function(experimental_relax_shapes=True)\n",
        "def forward_pass(x):\n",
        "    \"\"\"Prediccion.\"\"\"\n",
        "    out_x = gnn(x)\n",
        "    return out_x.nodes\n",
        "\n",
        "def logits_to_stats(y_true, node_logits):\n",
        "    \"\"\"Convert predicted logits to class stats.\"\"\"\n",
        "    loss = loss_fn(y_true, node_logits)\n",
        "    probs = tf.nn.softmax(node_logits)\n",
        "    acc = metric(y_true, probs).numpy()\n",
        "    return loss.numpy(), acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:23:38.511258Z",
          "start_time": "2020-08-25T13:21:00.537546Z"
        },
        "id": "ApqZ9BCQ20pY",
        "scrolled": true
      },
      "source": [
        "pbar = tqdm.tqdm(range(NUM_ITER))\n",
        "stats = defaultdict(list)\n",
        "\n",
        "for i in pbar:\n",
        "    with tf.GradientTape() as tape:\n",
        "      node_logits = forward_pass(x_train)\n",
        "      loss = loss_fn(y_train, node_logits)\n",
        "    grads = tape.gradient(loss, gnn.trainable_variables)\n",
        "    optimizer.apply_gradients((grad, var) \n",
        "    for (grad, var) in zip(grads, gnn.trainable_variables) \n",
        "    if grad is not None)\n",
        "    # Train statistics.\n",
        "    train_loss, train_acc = logits_to_stats(y_train, node_logits)\n",
        "    stats['train_loss'].append(train_loss)\n",
        "    stats['train_acc'].append(train_acc)\n",
        "    # Validation statistics.\n",
        "    node_logits = forward_pass(x_valid)\n",
        "    valid_loss, valid_acc = logits_to_stats(y_valid, node_logits)\n",
        "    stats['valid_loss'].append(valid_loss)\n",
        "    stats['valid_acc'].append(valid_acc)\n",
        "    # Update progress bar.\n",
        "    pbar.set_postfix({key:values[-1] for key, values in stats.items()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-25T13:25:16.159004Z",
          "start_time": "2020-08-25T13:25:15.541938Z"
        },
        "id": "YT2yMZ7r20pi"
      },
      "source": [
        "for key in ['train_loss','test_loss']:\n",
        "    plt.plot(stats[key],label=key)\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for key in ['train_acc','test_acc']:\n",
        "    plt.plot(stats[key],label=key)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}